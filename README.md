# LLAMA-2 Based Chatbot using GCP

## Overview

This project is a chatbot implementation that utilizes various technologies to provide users with an interactive and intelligent conversational experience. The chatbot is built with Streamlit chat components for the frontend interface, Google Cloud Platform for deployment, and the LLAMA-2 model from Google Model Garden for its core intelligence (also tried Gemini API and Gemma). Additionally, it integrates the Flask framework for backend communication and the Gemini API for access to financial data.

## Features

- **[Streamlit Chat Elemnents](https://docs.streamlit.io/develop/api-reference/chat)**: Provides an intuitive and user-friendly interface for interacting with the chatbot.
- **Google Cloud Platform**: Ensures scalability, reliability, and high-performance deployment of the chatbot models. Check [Model Garden](https://cloud.google.com/model-garden) fÄ±or latest models.
- **[LLAMA-2 Model](https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama2)**: Powers the chatbot's intelligence, offering robust natural language processing capabilities.
- **Flask Backend**: Facilitates communication between the frontend and deployed models, enabling real-time interaction.
- **Gemini API Integration**: Enhances the chatbot's functionality with access to a wide range of financial data and services.
- **Docker Integration**: Containerizes both the Flask backend and Streamlit frontend for easy deployment and portability.

## Usage



